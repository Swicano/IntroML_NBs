{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Math-OneHot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swicano/IntroML_NBs/blob/master/LSTM_Math_OneHot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek2_WxHDu3Iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "937f3611-51ed-4ea1-fc86-22665a5066a2"
      },
      "source": [
        "from keras import *\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APGhTBlWvLwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import *\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPKjT4EHvXij",
        "colab_type": "text"
      },
      "source": [
        "### Define a batch function and all that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF_OTS-kvXMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a function to generate arbitrary math problems\n",
        "\n",
        "def Gen_expr(terms=2, val_range=[1,10], trunc='{:.1f}', ops=['+','-','*','/'], rec_max=2, rec_ops = ['', 'sin','exp'], rec_prob = 0.33 ):\n",
        "  # rec refers to recursion, which is how i originally envisioned parentheticals and functions to be built\n",
        "  # but flattening arbitrarily recursive lists seemed like more work than just making flat ones to begin\n",
        "  rec_level = 0\n",
        "  expr_list = []\n",
        "  \n",
        "  term_list = [ trunc.format(random.uniform(val_range[0],val_range[1])) for i in range(terms) ]\n",
        "  ops_list = random.choices(ops,k=terms-1)\n",
        "  final = term_list.pop()\n",
        "  \n",
        "  # if someone puts in an empty rec list \n",
        "  if len(rec_ops)==0: \n",
        "    rec_ops = ['']\n",
        "    \n",
        "  while term_list:\n",
        "    if (rec_level<rec_max and random.random()<rec_prob):\n",
        "      rec_level+=1\n",
        "      expr_list.append( random.choice(rec_ops)+'(')\n",
        "    expr_list.append(term_list.pop())\n",
        "    if rec_level and random.random()<0.4:\n",
        "      rec_level-=1\n",
        "      expr_list.append(')')\n",
        "    expr_list.append(ops_list.pop())  \n",
        "  \n",
        "  # then finish off by adding the last number, and closing any open parens\n",
        "  expr_list.append(final)\n",
        "  while rec_level:\n",
        "    rec_level-=1\n",
        "    expr_list.append(')')\n",
        "  #expr_str = ''.join(expr_list)\n",
        "  \n",
        "  return expr_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h08ECrq86Ko-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_batch(batchsize = 1000, Encodings=False):\n",
        "  terms = 2\n",
        "  term_range = [1,9]\n",
        "  truncformat = '{:.0f}'  # the truncation format  '{:.1f}', {:.0f} for int\n",
        "  ops=['+']           # the potential operations supported\n",
        "  recs=['']               # the potential functions ('' = parens)\n",
        "  rec_prob = 0.33         # the probability of using one of the functions\n",
        "  max_term_len = max(len(truncformat.format(term_range[0])),len(truncformat.format(term_range[1])))\n",
        "  max_ops_len  = 1  #max([len(i) for i in ops])  # all ops are size one categories\n",
        "  max_rec_len  = 2  #max([len(i) for i in recs]) # recs are 'func(' & ')'\n",
        "  \n",
        "  inputlen =(max_term_len)*terms        # the +2 takes care of if each term somehow gets parens\n",
        "  inputlen+=max_ops_len*(terms-1)       # for the longest possible operations in each slot\n",
        "  inputlen+=int(max_rec_len*(rec_prob*terms+2)) # for the average number of function calls plus som wiggle\n",
        "  inputlen+=1                           # for the equals sign\n",
        "  outputlen=max_term_len+2              # assume the answer is max 1 digit larger (this is bad) (and sign)\n",
        "  encodings = 10+1+len(ops)+len(recs)-1+1+1 # digits0-9,'.', ops, recs-1, nesting, '='\n",
        "  enc_dict = {}\n",
        "  for i in range(10):\n",
        "    enc_dict[str(i)]=i\n",
        "  enc_dict['.']=10\n",
        "  enc_dict['=']=11\n",
        "  enc_dict['nest_depth']=12\n",
        "  for i,val in enumerate(ops):\n",
        "    enc_dict[val] = i+13\n",
        "  for i,val in enumerate(recs):\n",
        "    if val != '':\n",
        "      enc_dict[val] = i+13+len(ops)\n",
        "  enc_out = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'.':10,'+':11,'-':12}\n",
        "  \n",
        "  # dict is the better way i think\n",
        "  #encoding_labels = [i for i in range(10)]\n",
        "  #encoding_labels.append('.')\n",
        "  #encoding_labels.append('=')\n",
        "  #encoding_labels.append('nest_depth')\n",
        "  #encoding_labels.extend(ops)\n",
        "  #encoding_labels.extend(recs)\n",
        "  #encoding_labels.remove('')\n",
        "  #print(encodings, list(enc_dict), encoding_labels)\n",
        "  \n",
        "  # this does a one-hot style encoding\n",
        "  #                  informat = '{:>'+str(inputlen)+'}'\n",
        "  #                  outformat = '{:>'+str(outputlen)+'}'\n",
        "  inbatch  = zeros([batchsize, inputlen+outputlen,encodings])\n",
        "  outbatch = zeros([batchsize, inputlen+outputlen,len(enc_out)])\n",
        "  for i in range(batchsize):\n",
        "    # a hack since it could divide by 0\n",
        "    test = []\n",
        "    outtest = ''\n",
        "    while True:\n",
        "      try:\n",
        "        test = Gen_expr(terms=terms, val_range=term_range, trunc=truncformat, ops=ops, rec_max=2, rec_ops = recs, rec_prob =rec_prob)\n",
        "        outtest = truncformat.format(eval(''.join(test)))\n",
        "        #print(test,outtest, type(outtest))\n",
        "      except ZeroDivisionError:\n",
        "        #print(test, 'err!')\n",
        "        continue\n",
        "      else:\n",
        "        #do stuff?\n",
        "        break\n",
        "    in_vect = zeros([1,inputlen+outputlen,encodings])\n",
        "    out_vect = zeros([1,inputlen+outputlen,len(enc_out)])\n",
        "    \n",
        "    ### now we fill the input vector\n",
        "    # where we start adding it in in reverse order from the equals sign\n",
        "    loc = inputlen-1 \n",
        "    in_vect[0,loc,enc_dict['=']]=1\n",
        "    loc-=1\n",
        "    for op in test[::-1]:\n",
        "      in_vect[0,loc,enc_dict['nest_depth']]=in_vect[0,loc+1,enc_dict['nest_depth']]\n",
        "      #integers and non functions should end here\n",
        "      if op in enc_dict:\n",
        "        in_vect[0,loc,enc_dict[op]]=1\n",
        "      #if we are entering a function, there should be a '('\n",
        "      elif op[-1] =='(':\n",
        "        op2 = op[:-1]\n",
        "        # increase the nest depth (but in reverse)\n",
        "        in_vect[0,loc,enc_dict['nest_depth']]=in_vect[0,loc,enc_dict['nest_depth']]-1\n",
        "        # and check again if its in the dict\n",
        "        if op2 in enc_dict:\n",
        "          in_vect[0,loc,enc_dict[op2]]=1\n",
        "      # option 3 we are 'leaving' a nest\n",
        "      elif op == ')':\n",
        "        in_vect[0,loc,enc_dict['nest_depth']]=in_vect[0,loc,enc_dict['nest_depth']]+1\n",
        "      # option 4 we have floats!\n",
        "      elif set(op).issubset(set(enc_out)):\n",
        "        loc+=1\n",
        "        for char in list(op)[::-1]:\n",
        "          loc-=1\n",
        "          in_vect[0,loc,enc_dict['nest_depth']]=in_vect[0,loc+1,enc_dict['nest_depth']]\n",
        "          in_vect[0,loc,enc_dict[char]]=1\n",
        "      loc-=1 #increment the location\n",
        "    \n",
        "    \n",
        "    ### and then the output vector\n",
        "    loc=inputlen+outputlen-1\n",
        "    for char in list(outtest)[::-1]:\n",
        "      if char in enc_out:\n",
        "        out_vect[0,loc,enc_out[char]]=1\n",
        "      loc-=1\n",
        "    inbatch[i,:,:]=in_vect\n",
        "    outbatch[i,:,:]=out_vect\n",
        "  if Encodings:\n",
        "    return inbatch, outbatch ,enc_dict,enc_out,inputlen+outputlen\n",
        "  return  inbatch, outbatch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP05uTgjLU37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate our validation set, of which we will use number 1 to visualize\n",
        "Val_in, Val_out, Enc_in, Enc_out, seq_len = make_batch(1000, True)\n",
        "#print(Val_in[0], Val_out[0]) # subtract 48 to get the number value, 32='', 43='+', 61='=', 40='(', 41=')'\n",
        "#print(len(Enc_in), seq_len, len(Enc_out))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO7-pth-xx6M",
        "colab_type": "text"
      },
      "source": [
        "### Make the net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osyqWXD0xxVu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d8598ade-6590-43df-c828-f4e83d6a6719"
      },
      "source": [
        "net=Sequential()\n",
        "net.add(LSTM(30, batch_input_shape=[None,seq_len,len(Enc_in)], return_sequences=True))\n",
        "net.add(LSTM(len(Enc_out), return_sequences=True))\n",
        "net.add(Dense(len(Enc_out), activation = 'softmax'))\n",
        "net.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 01:03:21.515999 140293534541696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0703 01:03:21.587208 140293534541696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0703 01:03:21.595998 140293534541696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0703 01:03:22.183882 140293534541696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0703 01:03:22.212762 140293534541696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYDfC37o3uBS",
        "colab_type": "code",
        "outputId": "d90e30cb-9554-43e4-9a09-c43553589bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "epochs = 5000\n",
        "test_output = zeros([epochs, seq_len,len(Enc_out)])\n",
        "for k in range(epochs):\n",
        "  train_in, train_out = make_batch(3000)  # training data\n",
        "  bnet = net.train_on_batch(train_in, train_out)\n",
        "  test_output[k,:,:] = net.predict_on_batch(Val_in)[0,:,:]\n",
        "  if (k % 100 <1):\n",
        "    print(k, bnet)\n",
        "\n",
        "  #print(\"\\r epoch: \",k,\" deviation: \", sum((test_output[k,:,:]-Val_out[0,:,:])**2),\"    \")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [0.29174513, 0.055833332]\n",
            "100 [0.23594593, 0.053916667]\n",
            "200 [0.20388639, 0.057916667]\n",
            "300 [0.19124003, 0.06]\n",
            "400 [0.17846745, 0.07455555]\n",
            "500 [0.15252136, 0.085944444]\n",
            "600 [0.13548562, 0.102916665]\n",
            "700 [0.11637015, 0.124805555]\n",
            "800 [0.09715157, 0.13983333]\n",
            "900 [0.078169495, 0.14802778]\n",
            "1000 [0.06289512, 0.14327778]\n",
            "1100 [0.055015583, 0.14522222]\n",
            "1200 [0.045343842, 0.14783333]\n",
            "1300 [0.03938585, 0.15347221]\n",
            "1400 [0.03441919, 0.15427777]\n",
            "1500 [0.03170098, 0.15688889]\n",
            "1600 [0.027613495, 0.16211112]\n",
            "1700 [0.024729695, 0.16280556]\n",
            "1800 [0.021138558, 0.16275]\n",
            "1900 [0.018283296, 0.1635]\n",
            "2000 [0.01822145, 0.16025]\n",
            "2100 [0.014868323, 0.1621389]\n",
            "2200 [0.013826141, 0.16363889]\n",
            "2300 [0.01187484, 0.16533333]\n",
            "2400 [0.010415545, 0.164]\n",
            "2500 [0.008977785, 0.16452777]\n",
            "2600 [0.008523949, 0.1645]\n",
            "2700 [0.0076268464, 0.16433333]\n",
            "2800 [0.0066644954, 0.16619444]\n",
            "2900 [0.0060310136, 0.16580555]\n",
            "3000 [0.0057796286, 0.16527778]\n",
            "3100 [0.0052471305, 0.16488889]\n",
            "3200 [0.00502927, 0.16469444]\n",
            "3300 [0.004528663, 0.16341667]\n",
            "3400 [0.004131424, 0.16241667]\n",
            "3500 [0.003952112, 0.16375]\n",
            "3600 [0.0035507807, 0.16452777]\n",
            "3700 [0.0033986666, 0.16225]\n",
            "3800 [0.0030983184, 0.16280556]\n",
            "3900 [0.0027713235, 0.16316667]\n",
            "4000 [0.0026856046, 0.16208333]\n",
            "4100 [0.0026120385, 0.16177778]\n",
            "4200 [0.0024115022, 0.16077778]\n",
            "4300 [0.002151518, 0.15852778]\n",
            "4400 [0.0020657184, 0.15794444]\n",
            "4500 [0.0020098307, 0.15802778]\n",
            "4600 [0.0018914943, 0.15822223]\n",
            "4700 [0.001697597, 0.15877777]\n",
            "4800 [0.0015995019, 0.15755555]\n",
            "4900 [0.0015749796, 0.15888889]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utq8uwN9CKFk",
        "colab_type": "code",
        "outputId": "7c8c1f40-0454-4a0c-c456-80f621849bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(Val_out[0,:,:])\n",
        "print(test_output[-1,:,:])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "[[2.22862121e-02 7.91026950e-02 1.22578172e-02 2.90765706e-02\n",
            "  6.79574758e-02 9.80028585e-02 9.88000855e-02 1.89954221e-01\n",
            "  2.23821506e-01 5.07683307e-02 4.35735248e-02 4.41032536e-02\n",
            "  4.02953885e-02]\n",
            " [2.01242790e-02 1.72809824e-01 8.45929980e-03 2.06460021e-02\n",
            "  6.74936026e-02 8.07401463e-02 1.46998659e-01 1.65795475e-01\n",
            "  1.41591921e-01 4.92287017e-02 4.60697114e-02 4.15114611e-02\n",
            "  3.85308489e-02]\n",
            " [1.30038699e-02 4.21608180e-01 2.80397828e-03 8.49213544e-03\n",
            "  6.03497103e-02 3.25104520e-02 2.06622139e-01 9.68532413e-02\n",
            "  4.65702713e-02 3.37408297e-02 3.16055603e-02 2.32566837e-02\n",
            "  2.25830022e-02]\n",
            " [4.92729014e-03 7.86409914e-01 3.14334669e-04 1.97386066e-03\n",
            "  4.18451913e-02 2.19884794e-03 1.13318525e-01 1.59082133e-02\n",
            "  6.47271331e-03 9.89314076e-03 8.00102297e-03 4.35753819e-03\n",
            "  4.37944802e-03]\n",
            " [1.01391110e-03 9.50376749e-01 2.14575175e-05 4.57232643e-04\n",
            "  3.59541886e-02 2.74690919e-05 8.24796967e-03 5.96738595e-04\n",
            "  1.32992712e-03 4.50756284e-04 8.20769230e-04 3.59778380e-04\n",
            "  3.43085092e-04]\n",
            " [2.66056857e-04 9.91536379e-01 9.79091055e-06 1.54910420e-04\n",
            "  7.28708738e-03 8.20809191e-07 3.96056246e-04 1.98443831e-05\n",
            "  1.35735449e-04 1.99497354e-05 1.07926469e-04 3.51618801e-05\n",
            "  3.02881763e-05]\n",
            " [1.00854377e-04 9.99590814e-01 4.65353623e-05 5.29280660e-05\n",
            "  1.22388810e-04 8.05762639e-08 5.42167109e-05 3.69237114e-07\n",
            "  1.54059205e-06 3.63854429e-06 2.04954958e-05 3.38034624e-06\n",
            "  2.70148803e-06]\n",
            " [5.21031070e-05 9.99722064e-01 1.39583484e-04 3.63777835e-05\n",
            "  2.34819545e-05 3.55034366e-08 1.52334687e-05 3.57850318e-08\n",
            "  1.27280870e-07 8.30754004e-07 8.42081135e-06 9.95220489e-07\n",
            "  7.06453022e-07]\n",
            " [3.21882326e-05 9.99640107e-01 2.47224816e-04 4.48772807e-05\n",
            "  2.46354357e-05 4.23965218e-08 4.26450606e-06 1.09109672e-08\n",
            "  5.03422193e-08 3.02479378e-07 5.43657870e-06 5.41881604e-07\n",
            "  3.56193027e-07]\n",
            " [2.65051567e-05 9.99589503e-01 2.96968967e-04 5.13048071e-05\n",
            "  2.75873517e-05 4.75712731e-08 2.53564440e-06 7.26795824e-09\n",
            "  3.76008380e-08 2.01421472e-07 4.59815010e-06 4.29799968e-07\n",
            "  2.74378948e-07]\n",
            " [2.49549485e-05 9.99574602e-01 3.10889271e-04 5.33406928e-05\n",
            "  2.87199582e-05 4.95329679e-08 2.20886386e-06 6.48498011e-09\n",
            "  3.47786830e-08 1.80197731e-07 4.40123267e-06 4.04795827e-07\n",
            "  2.56306123e-07]\n",
            " [3.08822637e-04 2.17456208e-03 9.74866807e-01 2.15266068e-02\n",
            "  1.04273367e-03 1.36501749e-05 4.47451639e-05 6.26139425e-08\n",
            "  1.37269012e-06 1.68179176e-05 3.32772720e-06 3.42331475e-07\n",
            "  1.47456262e-07]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-LXtnvbdbhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "af720c49-9dc2-426d-cbc6-ee39b0147ee2"
      },
      "source": [
        "fig=plt.figure(figsize=(7,5))\n",
        "test_out = test_output[0::100,-1,:]\n",
        "plt.imshow(test_out,origin='upper',interpolation='nearest',aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEyCAYAAADQnlYUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkEiSOrGQSJI6sZBIkjr5/3cFDHSVyXOOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z28OHgKoP8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}